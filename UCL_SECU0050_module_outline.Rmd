---
title: "DATA SCIENCE FOR CRIME SCIENTISTS (UCL SECU0050)"
author: "Bennett Kleinberg (bennett.kleinberg@ucl.ac.uk)"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
subtitle: Department of Security and Crime Science, UCL
urlcolor: blue
---

## Introduction

This UG (Year 3) module builds on the quantitative modules of Year 1 (Probability, Statistics and Modelling I) and Year 2 (Probability, Statistics and Modelling II), and introduces data science techniques as means for more sophisticated quantitative data analysis. This module aims to introduce students to computational methods for crime science.

The techniques covered in this module will be of relevance to students undertaking their final year independent research project as well as to those who wish to pursue a career in a data science or analyst role.


## Dates & times

The module is running **online** in Term 2, 2020/2021, from 11 January 2021 - 26 March 2021.

_Note that due to COVID-19, this module is taught in a hybrid setup: lectures will be provided asynchronously, remotely (i.e., you can watch them at your own time each week), while tutorials are planned to be held in person._

- Time of tutorials: Mondays, 3:00 - 4:30pm

UCL timetable page: [https://timetable.ucl.ac.uk/tt/createCustomTimet.do#](https://timetable.ucl.ac.uk/tt/createCustomTimet.do#)

## Contact & resources

- Dr Bennett Kleinberg, Assistant Professor, bennett.kleinberg@ucl.ac.uk
- TA: Josh Kamps, Doctoral researcher, josh.kamps@ucl.ac.uk

The **moodle page** will accompany this module [here](https://moodle.ucl.ac.uk/course/view.php?id=11193).

**Walk-in office hour:** A virtual office hour will be held on XXX from XXX to XXX via Zoom (access details to be shared via Moodle). This office hour will include a "waiting room" and you are admitted to the office hour one after the other.

<!-- Q&A forum: if you have a questions/problem related to the content of the lectures/tutorials, then please use [the Q&A forum](https://moodle.ucl.ac.uk/course/view.php?id=11193&section=4). -->

## Learning outcomes

Upon successful completion of this module, you will be able to:

- demonstrate knowledge of a broader range of analytical techniques used in the field of Security and Crime Science
- understand the purpose, advantages and disadvantages of different forms of data science techniques
- perform data science analyses on crime and/or-security related issues
- apply the data science pipeline on crime and/or-security related issues
- interpret and effectively report the results of said techniques

## Learning hours

This module is worth 0.5 UCL credits (= 7.5 ECTS) which equals to 188 hours of study, i.e. 188h/11 weeks (incl reading week) = 17 hours per week.

_Note: the content structure and the assessment assumes that you spend on average that amount of time with this module._

| Component                    	| Amount 	| Duration 	| Total hours 	|
|------------------------------	|--------	|----------	|-------------	|
| Lectures                     	| 10     	| 1.5h     	| 15h         	|
| Tutorials/practicals         	| 10     	| 1.5h    	| 15h         	|
| Assessment: ML challenge    	| 1      	| 1h      	| 28h          	|
| Assessment: project          	| 1      	| 40h     	| 50h         	|
| Homework/revision/self-study 	| 10     	| 10h       | 80h         	|
| TOTAL                        	| -      	| -        	| 188h         	|

## Structure

The general structure of this module is as follows: there are four content blocks (web data collection, text mining, machine learning, advanced techniques) which each will be covered in weekly sessions consisting of lectures and tutorials. The lectures cover the approaches on a conceptual (what do they do?) and functional level (how do they work?). The tutorials are practical sessions in which you will learn how to implement the techniques in the R programming language. During the tutorials, there is assistance available to help you. 

Each week is (roughly) structured as follows:

- Reading and comprehending the required literature (necessary preparation for the lecture)
- Lecture (weekly content)
- Tutorial (practical implementation of lecture content)
- Homework (helps you consolidate the concepts and build your R skills portfolio)


## Timetable

_Date here refers to the release date of the lecture_

| UCL week 	| Module week 	| Date  	| Topic                    	|
|----------	|-------------	|--------	|--------------------------	|
| 20       	| 0           	|  4 Jan 	| Preparation + setup     	|
| 20       	| 1           	| 11 Jan 	| Web data collection I    	|
| 21       	| 2           	| 18 Jan 	| Web data collection II   	|
| 22       	| 3           	| 25 Jan 	| Text mining I            	|
| 23       	| 4           	|  1 Feb 	| Text mining II           	|
| 24       	| 5           	|  8 Feb 	| Text mining III          	|
| 25       	| -           	| -      	| READING WEEK             	|
| 26       	| 6           	| 22 Feb 	| Machine learning I       	|
| 27       	| 7           	|  1 Mar 	| Machine learning II      	|
| 28       	| 8           	|  8 Mar 	| Machine learning III     	|
| 39       	| 9           	| 15 Mar 	| Guest lecture 1          	|
| 30       	| 10          	| 22 Mar 	| Guest lecture 2          	|


## Content

_Note: slides and tutorials will be added as the module progresses._

### Week 0 - Module preparation and software setup

<!-- Please ensure that you follow the guides below to setup your computer with the necessary software. We also assume that you have a basic understanding of pragmatically solving coding problems. Do do this, please take the time to walk through the tutorial below. -->

<!-- - Tutorial guide: [R for crime scientists in 12 steps](https://rawcdn.githack.com/ben-aaron188/UCL_SECU0050/8cee7970ae540c8c23d04a308ec7e19cb732abc3/tutorials/week_0/r_in_12_steps.html) -->
<!-- - Tutorial guide: [Getting ready for R](https://rawcdn.githack.com/ben-aaron188/UCL_SECU0050/8cee7970ae540c8c23d04a308ec7e19cb732abc3/tutorials/week_0/getting_ready_for_r.html) -->
<!-- - Tutorial guide: [How to solve data science problems](https://rawcdn.githack.com/ben-aaron188/UCL_SECU0050/df0b0c3114f3fc804468bbcd831fc8345547b91a/tutorials/week_0/how_to_solve_data_science_problems.html) -->

### Week 1 - Web data collection I

- Topics covered: web data collection with APIs
- Required preparation
    - Morstatter, F., Pfeffer, J., Liu, H., & Carley, K. M. (2013). Is the Sample Good Enough? Comparing Data from Twitter’s Streaming API with Twitter’s Firehose. ArXiv:1306.5204 [Physics]. Retrieved from [http://arxiv.org/abs/1306.5204](http://arxiv.org/abs/1306.5204)
    - [MDN HTML basics](https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics), [MDN HTML tables](https://developer.mozilla.org/en-US/docs/Learn/HTML/Tables/Basics)
    - Recommended: Pfeffer, J., Mayer, K., & Morstatter, F. (2018). Tampering with Twitter’s Sample API. EPJ Data Science, 7(1), 50. [https://doi.org/10.1140/epjds/s13688-018-0178-0](https://doi.org/10.1140/epjds/s13688-018-0178-0)
    
<!-- - Slides: [Week 1: Web data collection 1](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/lectures/week_1/week1_secu0050.html), [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_1/week1_secu0050.pdf) -->
<!-- - Tutorial + Homework: [Tutorial, week 1: web data collection 1](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_1/week1_tutorial_secu0050.nb.html), [Tutorial solutions](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_1/week1_tutorial_secu0050_solutions.nb.html) -->

### Week 2 - Web data collection II

- Topics covered: HTML basics, web scraping in R
- Required preparation
    - [MDN Javascript basics](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/First_steps/What_is_JavaScript)
    - [MDN CSS first steps](https://developer.mozilla.org/en-US/docs/Learn/CSS/First_steps/Getting_started)
    - Ignatow & Mihalcea, 2018: C6 Web crawling
    - [Rvest package documentation](https://cran.r-project.org/web/packages/rvest/rvest.pdf)


<!-- - Slides: [Week 2: Web data collection 2](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/lectures/week_2/week2_secu0050.html), [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_2/week2_secu0050.pdf) -->
<!-- - Tutorial + Homework: [Tutorial, week 2: web data collection 2](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_2/week2_tutorial_secu0050.nb.html), [Tutorial solutions](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/tutorials/week_2/week2_tutorial_secu0050_solutions.Rmd) -->


### Week 3 - Text mining I

- Topics covered: quantification problem, TF-IDF, text metrics
- Required preparation
    - [Zipf's Mystery (YouTube)](https://www.youtube.com/watch?v=fCn8zs912OE)
    - Ignatow & Mihalcea, 2018: C7 Lexical resources
    - Ignatow & Mihalcea, 2018: C8 Basic text properties
    - Schoonvelde, M., Brosius, A., Schumacher, G., & Bakker, B. N. (2019). Liberals lecture, conservatives communicate: Analyzing complexity and ideology in 381,609 political speeches. PLOS ONE, 14(2), e0208450. [https://doi.org/10.1371/journal.pone.0208450](https://doi.org/10.1371/journal.pone.0208450)
    - [Quanteda quick start guide](https://quanteda.io/articles/quickstart.html)
- Recommended: 
    - [Regular expressions with stringr](https://stringr.tidyverse.org/articles/regular-expressions.html)
    - [Grolemund & Wickham, 2016: C14 Strings](https://r4ds.had.co.nz/strings.html)


<!-- - Slides: [Week 3: Text mining 1](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/lectures/week_3/week3_secu0050.html), [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_3/week3_secu0050.pdf) -->
<!-- - Tutorial + Homework: [Tutorial, week 3: Text mining 1](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_3/week3_tutorial_secu0050.nb.html), [Tutorial solutions](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_3/week3_tutorial_secu0050_solutions.nb.html) -->

### Week 4 - Text mining II

- Topics covered: POS tagging, ngrams, sentiment analysis, sentiment trajectories
- Required preparation:
    - Soldner, F., Ho, J. C., Makhortykh, M., van der Vegt, I. W. J., Mozes, M., & Kleinberg, B. (2019). Uphill from here: Sentiment patterns in videos from left- and right-wing YouTube news channels. Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science, 84–93. [https://doi.org/10.18653/v1/W19-2110](https://doi.org/10.18653/v1/W19-2110)
    - Kleinberg, B., Mozes, M., & van der Vegt, I. (2018). Identifying the sentiment styles of YouTube’s vloggers. 3581–3590. [https://www.aclweb.org/anthology/D18-1394](https://www.aclweb.org/anthology/D18-1394)
    - Gao, J., Jockers, M. L., Laudun, J., & Tangherlini, T. (2016). A multiscale theory for the dynamical evolution of sentiment in novels. Behavioral, Economic and Socio-Cultural Computing (BESC), 2016 International Conference On, 1–4.
- Recommended:
    - Jockers, M. (2015). Revealing Sentiment and Plot Arcs with the Syuzhet Package. http://www.matthewjockers.net/2015/02/02/syuzhet/

<!-- - Slides: [Week 4: Text mining 2](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/lectures/week_4/week4_secu0050.html), [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_4/week4_secu0050.pdf) -->
<!-- - Tutorial+ Homework: [Tutorial: week 4: Text mining 2](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_4/week4_tutorial_secu0050.nb.html), [Tutorial solutions](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_4/week4_tutorial_secu0050_solutions.nb.html) -->

### Week 5 - Text mining III

- Topics covered: text similarity, word embeddings
- Required preparation
    - [Introduction to word embeddings, Mozes (2019)](https://github.com/maximilianmozes/word_embeddings_workshop_resources/blob/master/slides/theo.pdf)
    - Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global Vectors for Word Representation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 1532–1543. [https://doi.org/10.3115/v1/D14-1162](https://doi.org/10.3115/v1/D14-1162) from [https://nlp.stanford.edu/pubs/glove.pdf](https://nlp.stanford.edu/pubs/glove.pdf)
    - Mikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013). Distributed Representations of Words and Phrases and their Compositionality. ArXiv:1310.4546 [Cs, Stat]. [http://arxiv.org/abs/1310.4546](http://arxiv.org/abs/1310.4546)
    - Vector dot products from [https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/dot-cross-products/v/vector-dot-product-and-vector-length](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/dot-cross-products/v/vector-dot-product-and-vector-length)
    - Matrix vector products from [https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/matrix-vector-products](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/matrix-vector-products)
    - [Limitations of word embeddings, Burdick, 2019](https://github.com/maximilianmozes/word_embeddings_workshop_resources/blob/master/slides/limitations.pdf)
    - Wendlandt, L., Kummerfeld, J. K., & Mihalcea, R. (2018). Factors Influencing the Surprising Instability of Word Embeddings. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), 2092–2102. [https://doi.org/10.18653/v1/N18-1190](https://doi.org/10.18653/v1/N18-1190)
- Recommended:
    - Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the National Academy of Sciences, 115(16), E3635–E3644. [https://doi.org/10.1073/pnas.1720347115](https://doi.org/10.1073/pnas.1720347115)
    - Bolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V., & Kalai, A. (2016). Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings. ArXiv:1607.06520 [Cs, Stat]. [http://arxiv.org/abs/1607.06520](http://arxiv.org/abs/1607.06520)
    - Vylomova, E., Rimell, L., Cohn, T., & Baldwin, T. (2016). Take and Took, Gaggle and Goose, Book and Read: Evaluating the Utility of Vector Differences for Lexical Relation Learning. ArXiv:1509.01692 [Cs]. [http://arxiv.org/abs/1509.01692](http://arxiv.org/abs/1509.01692)

<!-- - Slides: [Week 5: Text mining 3](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/lectures/week_5/week5_secu0050.html), [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_5/week5_secu0050.pdf) -->
<!-- - Tutorial + Homework: [Tutorial, week 5: Text mining 3](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_5/week5_tutorial_secu0050.nb.html), [Tutorial solutions](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/tutorials/week_5/week5_tutorial_secu0050_solutions.Rmd) -->


### Week 6 - Machine learning I

- Topics covered: supervised machine learning (classification), core algorithms, performance metrics
- Required preparation
    - Ignatow & Mihalcea, 2018: C13 Text classification
    - Ignatow & Mihalcea, 2018: C9 Supervised learning
    - [Gatto, 2019: Supervised learning](https://lgatto.github.io/IntroMachineLearningWithR/supervised-learning.html)
    - [Deisenroth et al., 2019: C12 Classification with Support Vector Machines](https://mml-book.github.io/book/mml-book.pdf)
    - [Kuhn, 2019: C17 Measuring performance](https://topepo.github.io/caret/measuring-performance.html)
- Recommended:
    - [Kuhn, 2019: C5 Model training](https://topepo.github.io/caret/model-training-and-tuning.html)
    - [YT, 3Blue1Brown: Bayes theorem, and making probability intuitive](https://www.youtube.com/watch?v=HZGCoVF3YvM)

<!-- - Slides: [Week 7: Machine Learning 1](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/lectures/week_7/week7_secu0050.html), [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_7/week7_secu0050.pdf) -->
<!-- - Tutorial + Homework: [Tutorial, week 7: Machine Learning 1](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_7/week7_tutorial_secu0050.nb.html), [Tutorial solutions](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_7/week7_tutorial_secu0050_solutions.nb.html) -->

### Week 7 - Machine learning II

- Topics covered: unsupervised machine learning, core algorithm, problems
- Required preparation
    - [Gatto, 2019: C4 Unsupervised learning](https://lgatto.github.io/IntroMachineLearningWithR/unsupervised-learning.html)
    - Denny, M. J., & Spirling, A. (2018). Text Preprocessing For Unsupervised Learning: Why It Matters, When It Misleads, And What To Do About It. Political Analysis, 26(2), 168–189. [https://doi.org/10.1017/pan.2017.44](https://doi.org/10.1017/pan.2017.44)
- Recommended:
    - [Datacamp unsupervised learning](https://www.datacamp.com/courses/unsupervised-learning-in-r)


<!-- - Slides: [Week 8: Machine Learning 2](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/lectures/week_8/week8_secu0050.html), [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_8/week8_secu0050.pdf) -->
<!-- - Tutorial + Homework: [Tutorial, week 8: Machine Learning 2](https://raw.githack.com/ben-aaron188/UCL_SECU0050/master/tutorials/week_8/week8_tutorial_secu0050.nb.html), [Tutorial solutions](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/tutorials/week_8/week8_tutorial_secu0050_solutions.Rmd) -->


### Week 8 - Machine learning III

Guest lecture: Josh Kamps

- Topics covered: neural networks in R, intro to deep learning
- Required preparation:
    - Domingos, P. (2012). A few useful things to know about machine learning. Communications of the ACM, 55(10), 78. https://doi.org/10.1145/2347736.2347755
    - Nielsen, M. A. (2015). Neural Networks and Deep Learning. http://neuralnetworksanddeeplearning.com

<!-- - Slides: [Week 9 : Machine Learning 3](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/lectures/week_9/week9_secu0050.pdf) -->
<!-- - Tutorial + homework: [Tutoriall, week 9: Machine Learning 3](https://raw.githack.com/JoshKamps/JoshKamps.github.io/master/week9_tutorial_secu0050.nb.html#) -->


### Week 9 - Guest lecture 1

tbd.

<!-- This lecture includes two guest talks: -->

<!-- - Maximilian Mozes - "On the robustness of intelligent systems"  -->
<!-- - Isabelle van der Vegt - "Data Science for Threat Assessment"  -->

<!-- - Required preparation -->
<!--     - Gu, T., Dolan-Gavitt, B., & Garg, S. (2019). BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain. ArXiv:1708.06733 [Cs]. Retrieved from [http://arxiv.org/abs/1708.06733](http://arxiv.org/abs/1708.06733) -->
<!--     - Kurakin, A., Goodfellow, I., & Bengio, S. (2017). Adversarial examples in the physical world. ArXiv:1607.02533 [Cs, Stat]. Retrieved from [http://arxiv.org/abs/1607.02533](http://arxiv.org/abs/1607.02533) -->
<!--     - Azucar, D., Marengo, D., & Settanni, M. (2018). Predicting the Big 5 personality traits from digital footprints on social media: A meta-analysis. Personality and Individual Differences, 124, 150–159. [https://doi.org/10.1016/j.paid.2017.12.018](https://doi.org/10.1016/j.paid.2017.12.018) -->
<!--     - van der Vegt, I., Mozes, M., Gill, P., & Kleinberg, B. (2019). Online influence, offline violence: Linguistic responses to the “Unite the Right” rally. ArXiv:1908.11599 [Cs]. Retrieved from http://arxiv.org/abs/1908.11599 -->
<!-- - Slides: _video-recorded lectures due to the Corona virus situation_ -->
<!-- - Tutorial + Homework: _This tutorial will give you time to work on your final project under our guidance._ -->

### Week 10 - Guest lecture 2

tbd.


## Materials

### Software

We will use the R programming language. All packages, required resources and tools needed are openly available and free to download to any computer. We strongly encourage students to bring their own laptops to the tutorials so they can customise their work environment. However, we will have a computer cluster available where you can use the UCL computers.

### Literature

You can find the required reading (as well as suggested further reading) in the table above and on the moodle page.)

For each week, the required literature includes one reading on techniques/tools that are important for data science projects but are not covered in the lectures or tutorials. You will likely need these techniques in the project and we assume that you have read and prepared the reading so that you are able to use the techniques.


Key resources for this module are:

- [An Introduction to Text Mining](http://us.sagepub.com/en-us/nam/an-introduction-to-text-mining/book249451#contents) (Ignatow & Mihalcea, 2018) - SAGE
    - _UCL library services have ordered a few copies of this book_
    - You can buy the book at a UCL student discount via this link [https://studysites.uk.sagepub.com/dts-studentdeal/](https://studysites.uk.sagepub.com/dts-studentdeal/)
- Text mining with R (Silge & Robinson, 2019) - interactive book version freely available at [https://www.tidytextmining.com/](https://www.tidytextmining.com/)
- Mathematics for Machine Learning (Deisenroth et al., 2019) - freely available at [https://mml-book.github.io/book/mml-book.pdf](https://mml-book.github.io/book/mml-book.pdf)
- R for Data Science (Grolemund & Wickham, 2016) - interactive book version freely available at [https://r4ds.had.co.nz/](https://r4ds.had.co.nz/)
- The Caret package (Kuhn, 2019) - interactive book version freely available at [https://topepo.github.io/caret/index.html](https://topepo.github.io/caret/index.html)
- Machine learning with R (Gatto, 2019) - interactive book version freely available at [https://lgatto.github.io/IntroMachineLearningWithR/index.html](https://lgatto.github.io/IntroMachineLearningWithR/index.html)
- Applied Predictive Modelling (Kuhn & Johnson, 2013) - this book is freely available to you as UCL student through UCL Library's [free e-book access](https://ucl-new-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=TN_springer_s978-1-4614-6849-3_216330&context=PC&vid=UCL_VU2&lang=en_US&search_scope=CSCOP_UCL&adaptor=primo_central_multiple_fe&tab=local&query=any,contains,Applied%20Predictive%20Modeling&offset=0).

Other useful resources:

- Data Visualization with R (Kabacoff, 2018) - interactive book version freely available at [https://rkabacoff.github.io/datavis/](https://rkabacoff.github.io/datavis/), especially:
    - [Kabacoff, 2018: C2 Intro to ggplot2](https://rkabacoff.github.io/datavis/IntroGGPLOT.html)
    - [Kabacoff, 2018: C3 Univariate graphs](https://rkabacoff.github.io/datavis/Univariate.html)
    - [Kabacoff, 2018: C4 Bivariate graphs](https://rkabacoff.github.io/datavis/Bivariate.html)
    - [Kabacoff, 2018: C5 Multivariate graphs](https://rkabacoff.github.io/datavis/Multivariate.html)
- [Quanteda text visualisation](https://quanteda.io/articles/pkgdown/examples/plotting.html) -->

### Data

All datasets used are open-source and available without restrictions.

## Assessment

### Machine Learning challenge

- Weight for final grade: 30%
- Learning outcomes tested: (1) demonstrating knowledge of a broader range of analytical techniques used in the field of Security and Crime Science, (2) understanding the purpose, advantages and disadvantages of different forms of data science techniques, (3) interpreting the results of data science techniques.
- Deadline: 24 March 2021, 4pm

#### Background

In this part of the assessment, you can put your text mining and machine learning skills to use. The machine learning challenge is inspired by so-called "shared tasks" and Kaggle-challenges where many researchers/analysts compete against each other in solving one problem.

The problem is typically a classification challenge: you are provided with training data that allow you to build a classification system that learns to differentiate between two (or more) outcomes. For example, the training data could consist of movie reviews and a label associated with them (e.g. positive review vs negative review). The task is to build a classification system (i.e. extracting variables needed for classification and choosing algorithms) that you submit and evaluate at a later stage on unseen (i.e. new) data (so-called test data).

_Note: in order to do this challenge, you need to have done and understood the content covered in weeks 3-8 (i.e. on text mining and machine learning)._

#### Details

The machine learning challenge for this module is hosted on [Kaggle](https://www.kaggle.com/) and accessible at the start of week 3 of the module (25 Jan 2021).

You will find all details on the dedicated Kaggle page for this assessment.

<!-- Possible: emotion detection, pos neg classification, adv perturb detection -->

The workflow consists of these steps:

- you get access to the training data via Kaggle
- you can find the details of the dataset and the classification problem on the Kaggle competition page
- use the training dataset to build a classification system that best addresses the problem (note: you will have to make many decisions while doing this, make sure to document these properly in your code)
- if you are happy with how your model works, you can submit it on Kaggle
- submitting the work on Kaggle triggers an automatic evaluation of your model against 30% of the unseen test dataset
- ...


#### Deliverables

The core of this assessment is your work in the Kaggle challenge.  

- Report: use the report template (TO BE MADE AVAILABLE) to detail your approach and findings. The word count limit is **750 words**.
- Presentation: ...


#### Grading criteria

| Criterion             | Meaning                                                                               | Weight |
|-----------------------|---------------------------------------------------------------------------------------|--------|
| Best submission       | The quality, innovativeness and appropriateness of the best-performing ML solution    | 25%    |
| Poorest submission    | The quality, innovativeness and appropriateness of the poorest-performing ML solution | 25%    |
| Quality of the R code | The quality of the R code for the best submission                                     | 20%    |
| Presentation          | The clarity and content of the presentation                                           | 15%    |
| Quality of the report | The clarity, layout, formatting and overall quality of the written report.            | 15%    |

### Applied Data Science Project

- Weight for final grade: 70%
- Learning outcomes tested: (1) demonstrating knowledge of a broader range of analytical techniques used in the field of Security and Crime Science, (2) performing data science analyses on crime and/or-security related issues, (3) applying the data science pipeline on crime and/or-security related issues, (4) interpreting and effectively reporting the results of said techniques
- Deadline: 26 April 2021, 4pm.
- Page limit: See below.
<!-- - Assessment details as [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/assessment/SECU0050_project_assignment.pdf) -->

> _This assessment is the capstone project of the module. It requires you to address a research problem in the full data science workflow (e.g., obtaining the data, processing the data, modelling the data, building predictive models, reporting on the findings, interpreting the outcomes). You will write a brief report on your project (a template will be provided) and you have to submit the R code needed to reproduce your findings. After passing this assessment, you will have the demonstrated the skills to solve a problem using data science techniques._

<!-- #### Feedback  -->

<!-- A full project is a major step in your data science skills career. To help you in the process, you will receive feedback from us on a concept draft of your project. The deadline for the concept draft is **9 March 2020 (4pm)** via Turn-it-in on moodle. The requirements for the feedback submission are available on moodle. _The submission of the concept draft accounts for 10% of the Applied Data Science Project._  -->

<!-- - Feedback form template for submission as [PDF](https://github.com/ben-aaron188/UCL_SECU0050/blob/master/assessment/project_concept_draft_template.pdf). -->

#### Assessment topic

<!-- This year's topic is authorship attribution. Recently, an area of digital forensics closely connected to NLP that seeks to identify who wrote a piece of text/novel/song/etc. has received considerable attention (e.g., [Why Molière most likely did write his plays](https://advances.sciencemag.org/content/5/11/eaax5489.abstract), [Researcher uses AI to unravel the mystery of Shakespeare’s co-author](https://thenextweb.com/artificial-intelligence/2019/11/27/ai-shakespeare-henry-viii/), and [Plecháč, 2019](https://arxiv.org/abs/1911.05652)). -->

<!-- With more techniques at the researchers' disposal, this area is likely to impact on how we do digital forensic investigations (e.g. when trying to find who wrote a post). The project requires you to conduct your own authorship attribution project including (web) data collection, text processing and text mining, and approaches to identify authorship (e.g. through machine learning). _The exact nature of the project is up to you._ **The only restriction on the topic is that you must not use novels as the source of data**. -->

<!-- Further details: -->

<!-- - the project should be on authorship attribution (not author profiling) -->
<!-- - all steps in this project must be reproducible with your code supplement -->
<!-- - the project should have a large-scale focus (i.e. not a case study with one document) -->
<!-- - all three core areas of this module should be used: web data collection, text mining, machine learning -->


#### The code supplement

Submit your R code in the form of a commented R notebook. To ensure that no code is lost and that we can review all code equally, submit your code as an anonymised view-only version on the [Open Science Framework](https://osf.io/). Create a private repository, upload your code as an R notebook and create an anonymised, view-only link that you include in your report (for a guide on creating that link, see [here](https://help.osf.io/hc/en-us/articles/360019930333-Create-a-View-only-Link-for-a-Project)). For details on reporting your code as an R notebook, you can consult these guides: [guide 1](https://bookdown.org/yihui/rmarkdown/notebook.html), [guide 2](http://uc-r.github.io/r_notebook).

#### The report

For this assignment, you are asked to report your findings in the form of a short paper. Specifically, you should use the template of the ACL conference proceedings (these can be downloaded  [here for Latex and Word](http://acl2020.org/downloads/acl2020-templates.zip) or can be imported into Overleaf [here](https://www.overleaf.com/latex/templates/acl-2020-proceedings-template/zsrkcwjptpcd)).

Additional requirements for the report:

- use the ACL style guidelines (easiest through the templates)
- the **page limit is 5 content pages** + unlimited pages for the reference list
- use the ACL referencing style (this is available in reference managers like Zotero or handled directly in Overleaf) - i.e. adhere to their font type, font size and heading guidelines.
- use the anonymous submission version which contains line numbers
- the paper must contain only your examination number in the author line
- include a footnote with an anonymised view-only link to your code on the OSF (see above).
- submit the report via moodle as a pdf file using the following file name: _SECU0050_12345.pdf_ (replace 12345 with your examination number)


#### Grading criteria

| Criterion                          | Meaning                                                                                                                                            | Weight |
|------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|--------|
| Originality of project             | The degree to which the student demonstrates insight and is able to use an innovative approach to address the research problem.                    | 20%    |
| Quality of data science techniques | The degree to which the techniques used in this project are appropriate to answer the research question and are utilised and interpreted properly. | 50%    |
| Quality of the R code              | The degree to which the R code is well-documented, reproducible (with provided data if needed), and correct.                                       | 15%    |
| Quality of the report              | The clarity, layout, formatting and overall quality of the written report.                                                                         | 15%    |

## Attendance requirement

We are obliged to record the attendance at all sessions (lectures and tutorials) and each student will have to attend at least 70% of the sessions to be able to pass the module. If you cannot attend for a good reason, please let the TA know about this well in advance. *We strongly advise you to attend all sessions as this eases the assessment for you and will help you get the most out of this module.*

------


